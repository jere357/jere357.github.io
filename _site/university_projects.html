<!DOCTYPE html>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<html lang="en-US">
  <head>
    <title>
      Jere's web
    </title>
    <link rel="icon" type="image/x-icon" href="/assets/img/pinky.png">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Figure 1. Jeronim with his 1070TI GPU, that has fans from aliexpress that don’t really fit so he has to reapply the duct tape every now and then." />
<meta property="og:description" content="Figure 1. Jeronim with his 1070TI GPU, that has fans from aliexpress that don’t really fit so he has to reapply the duct tape every now and then." />
<link rel="canonical" href="http://localhost:4000/university_projects.html" />
<meta property="og:url" content="http://localhost:4000/university_projects.html" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Figure 1. Jeronim with his 1070TI GPU, that has fans from aliexpress that don’t really fit so he has to reapply the duct tape every now and then.","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/ja.jpeg"}},"url":"http://localhost:4000/university_projects.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style2.css?v=">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->

    
    <!-- for mathjax support -->
    
    



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

    
    <style>
      /* Dark mode styles */
      body.dark-mode {
        background-color: #222; /* Dark background color */
        color: #ccc; /* Light text color */
      }


      body.dark-mode p, 
      body.dark-mode a,
      body.dark-mode h1,
      body.dark-mode h2,
      body.dark-mode h3 {
        color: #ccc; /* Text color for paragraphs, links, h1, and h3 */
      }

      /* Set color for links */
      body.dark-mode a {
    color: rgba(96, 138, 230, 0.795); /* Set link color to blue */
  }
    </style>
  </head>
  <body class="dark-mode">
    <div class="wrapper">
      <section>
        <p><a href="./">Home</a> / <a href="./blog_index.html">Blog</a></p>

<h1 id="university-projects-w-deep-learning">University projects w/ deep learning</h1>

<p>In this document, I showcase several deep learning/machine learning projects that I completed during my time as a university student. These projects cover a variety of applications in natural language processing, computer vision, and generative modeling.</p>

<h2 id="method-for-people-counting-from-image-sequence">Method for People Counting From Image Sequence</h2>
<p>My BSc thesis. I located people in a single image using the tinyface detector (it was clearly the best of all methods we observed (at that time)) and then devel-
oped an algorithm that created trajectories and followed/counted people from frame to frame in a video. Thanks to Nikola Banić for his guidance while i was working on this.</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=XzzDttREG-o">Youtube demo I uploaded in communication with Nikola</a></li>
</ul>

<h2 id="music-genre-classification-from-lyrics">Music genre classification from lyrics</h2>

<p>We had a dataset composed of 250k song lyrics and their respective genres. The part I worked on was creating a tfidf weighted fasttext vector
from the top 10 ranked words in the song, and then finding the best classification algorithm. To no one’s surprise, it was XGBoost</p>

<ul>
  <li><a href="https://www.fer.unizg.hr/_download/repository/TAR-2019-ProjectReports.pdf#section*.15">Project report</a></li>
  <li><a href="https://www.kaggle.com/code/sajithdherath/starter-380-000-lyrics-from-24ddf566-9/notebook">MetroLyrics dataset</a></li>
</ul>

<h2 id="pix2pixgan-for-generating-facial-expressions">Pix2pixGAN for generating facial expressions</h2>
<p>We trained a pix2pix GAN. The dataset had neutral facial expression image, an image with some emotion,
and the corresponding emotion vector, the results were surprisingly good. Network inputs were: face image with neutral expression + emotion
encoded in a vector output: face image with drawn emotion</p>

<ul>
  <li><a href="https://drive.google.com/file/d/1R-Hhop7eXfG4Eu4uMDlqt0fVyCT2dNHp/view">Project report (in Croatian)</a></li>
  <li><a href="https://paperswithcode.com/dataset/ck">CK+ dataset</a></li>
</ul>

<h2 id="retinal-fluid-segmentation-using-2d-u-net">Retinal fluid segmentation using 2D U-net</h2>
<p>This was done as my graduate project, the dataset I had was the same one used in the Retouch Challenge. Experimented with different/new
loss functions and observed how the end result changes with respect to the loss function with interesting results</p>

<ul>
  <li><a href="https://retouch.grand-challenge.org/">Retouch Challenge website</a></li>
</ul>

<h2 id="using-esrgan-for-achieving-superresolution">Using ESRGAN for achieving superresolution</h2>

<p>A seminar on  GANs and how they could be used for superresolution in images, and various difficulties the traditional approach had in achieving
superresolution. I’m a big fan of how GANs work for superresolution.</p>

      </section>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>
